import streamlit as st
import openrouteservice
from openrouteservice import convert
import google.generativeai as genai
import speech_recognition as sr
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder
import io
import tempfile
import os

# --- Cáº¤U HÃŒNH ---
st.set_page_config(page_title="Bus Assistant (Free Version)", page_icon="ğŸšŒ", layout="wide")

# --- QUáº¢N LÃ SECRETS ---
try:
    # Key báº£n Ä‘á»“ miá»…n phÃ­ (OpenRouteService)
    ORS_API_KEY = st.secrets.get("ORS_API_KEY", "") 
    # Key AI (Váº«n dÃ¹ng Gemini vÃ¬ nÃ³ free)
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
except:
    st.error("âš ï¸ ChÆ°a cáº¥u hÃ¬nh Secrets. Vui lÃ²ng thÃªm ORS_API_KEY vÃ  GEMINI_API_KEY.")
    st.stop()

if not ORS_API_KEY:
    # Náº¿u cháº¡y local mÃ  chÆ°a cÃ³ secrets, nháº­p táº¡m vÃ o Ä‘Ã¢y Ä‘á»ƒ test
    ORS_API_KEY = st.text_input("Nháº­p OpenRouteService Key (Miá»…n phÃ­):", type="password")

# --- HÃ€M TÃŒM Äá»ŠA ÄIá»‚M & ÄÆ¯á»œNG ÄI (DÃ¹ng OpenRouteService) ---
def get_coordinates(address, client):
    """Äá»•i Ä‘á»‹a chá»‰ thÃ nh tá»a Ä‘á»™ (Geocoding)"""
    try:
        geocode = client.pelias_search(text=address)
        if geocode['features']:
            # Láº¥y tá»a Ä‘á»™ Ä‘iá»ƒm Ä‘áº§u tiÃªn tÃ¬m tháº¥y [long, lat]
            coords = geocode['features'][0]['geometry']['coordinates']
            label = geocode['features'][0]['properties']['label']
            return coords, label
        return None, None
    except Exception as e:
        return None, str(e)

def get_route_ors(start_addr, end_addr, client):
    """TÃ¬m Ä‘Æ°á»ng Ä‘i bá»™/xe (Sá»­a lá»—i return type)"""
    # 1. TÃ¬m tá»a Ä‘á»™ Ä‘iá»ƒm Ä‘i/Ä‘áº¿n
    start_coords, start_label = get_coordinates(start_addr, client)
    end_coords, end_label = get_coordinates(end_addr, client)
    
    # [FIX Lá»–I Táº I ÄÃ‚Y]: Tráº£ vá» None trÆ°á»›c, Error sau
    if not start_coords or not end_coords:
        missing = start_addr if not start_coords else end_addr
        return None, f"KhÃ´ng tÃ¬m tháº¥y Ä‘á»‹a Ä‘iá»ƒm: {missing}. Vui lÃ²ng nháº­p cá»¥ thá»ƒ hÆ¡n (VÃ­ dá»¥: thÃªm 'TPHCM')."

    try:
        # 2. TÃ¬m Ä‘Æ°á»ng
        route = client.directions(
            coordinates=[start_coords, end_coords],
            profile='foot-walking', 
            format='geojson',
            language='vi'
        )
        
        # 3. TrÃ­ch xuáº¥t thÃ´ng tin
        summary = route['features'][0]['properties']['segments'][0]
        distance_km = round(summary['distance'] / 1000, 2)
        duration_min = round(summary['duration'] / 60)
        
        steps = summary['steps']
        step_text = ""
        for step in steps:
            step_text += f"- {step['instruction']} ({step['distance']}m)\n"

        return {
            "start": start_label,
            "end": end_label,
            "distance": f"{distance_km} km",
            "duration": f"{duration_min} phÃºt Ä‘i bá»™",
            "steps": step_text,
            "raw_steps": steps
        }, None

    except Exception as e:
        return None, f"Lá»—i tÃ¬m Ä‘Æ°á»ng: {str(e)}"
        
# --- CÃC HÃ€M Ã‚M THANH (GIá»® NGUYÃŠN) ---
def text_to_speech(text):
    try:
        tts = gTTS(text=text, lang='vi')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except: return None

def process_audio(audio_bytes):
    r = sr.Recognizer()
    try:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp:
            tmp.write(audio_bytes)
            name = tmp.name
        with sr.AudioFile(name) as src:
            audio = r.record(src)
            text = r.recognize_google(audio, language="vi-VN")
        os.remove(name)
        return text
    except: return None

# --- GIAO DIá»†N ---
st.title("ğŸšŒ Trá»£ LÃ½ Di Chuyá»ƒn (Báº£n Miá»…n PhÃ­)")
st.caption("Dá»¯ liá»‡u báº£n Ä‘á»“ tá»« OpenStreetMap & AI Gemini")

# Setup Client
if ORS_API_KEY:
    ors_client = openrouteservice.Client(key=ORS_API_KEY)

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel('gemini-flash-latest')

col1, col2 = st.columns([1, 1])

# Cá»˜T 1: TÃŒM ÄÆ¯á»œNG
with col1:
    st.subheader("ğŸ“ Nháº­p lá»™ trÃ¬nh")
    start_in = st.text_input("Äiá»ƒm Ä‘i", "Chá»£ Báº¿n ThÃ nh")
    end_in = st.text_input("Äiá»ƒm Ä‘áº¿n", "Dinh Äá»™c Láº­p")
    
    if st.button("TÃ¬m Ä‘Æ°á»ng"):
        if ORS_API_KEY:
            with st.spinner("Äang tÃ¬m trÃªn báº£n Ä‘á»“ má»Ÿ..."):
                data, err = get_route_ors(start_in, end_in, ors_client)
                
                if err:
                    st.error(err)
                elif data:
                    st.success(f"Tá»«: {data['start']}\nÄáº¿n: {data['end']}")
                    st.metric("Khoáº£ng cÃ¡ch", data['distance'], data['duration'])
                    
                    # Context cho AI
                    # Máº¸O: VÃ¬ ORS Free khÃ´ng cÃ³ dá»¯ liá»‡u xe buÃ½t tá»‘t, ta nhá» AI "chÃ©m" dá»±a trÃªn Ä‘á»‹a Ä‘iá»ƒm
                    context = f"""
                    NgÆ°á»i dÃ¹ng muá»‘n Ä‘i tá»« {data['start']} Ä‘áº¿n {data['end']}.
                    Khoáº£ng cÃ¡ch thá»±c táº¿: {data['distance']}. Thá»i gian Ä‘i bá»™: {data['duration']}.
                    Chi tiáº¿t Ä‘Æ°á»ng Ä‘i bá»™: {data['steps']}
                    """
                    st.session_state['route_context'] = context
                    st.session_state['location_data'] = data
                    
                    with st.expander("Xem hÆ°á»›ng dáº«n Ä‘i bá»™"):
                        st.text(data['steps'])
        else:
            st.warning("Vui lÃ²ng nháº­p API Key ORS.")

# Cá»˜T 2: CHAT AI TÆ¯ Váº¤N XE BUÃT
with col2:
    st.subheader("ğŸ¤– AI TÆ° Váº¥n Xe BuÃ½t")
    
    # Hiá»ƒn thá»‹ chat
    if "messages" not in st.session_state: st.session_state.messages = []
    for m in st.session_state.messages: st.chat_message(m["role"]).write(m["content"])

    # Input
    mic = mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='mic_btn')
    txt = st.chat_input("Há»i vá» xe buÃ½t tuyáº¿n nÃ y...")
    
    final_input = txt
    if mic and ('last_id' not in st.session_state or st.session_state.last_id != mic['id']):
        st.session_state.last_id = mic['id']
        t = process_audio(mic['audio']['bytes'])
        if t: final_input = t

    if final_input:
        st.session_state.messages.append({"role":"user", "content":final_input})
        st.chat_message("user").write(final_input)
        
        # PROMPT Äáº¶C BIá»†T Äá»‚ BÃ™ Äáº®P THIáº¾U Dá»® LIá»†U GOOGLE MAPS
        ctx = st.session_state.get('route_context', '')
        prompt = f"""
        Báº¡n lÃ  trá»£ lÃ½ xe buÃ½t thÃ´ng minh táº¡i Viá»‡t Nam.
        Hiá»‡n táº¡i há»‡ thá»‘ng báº£n Ä‘á»“ chá»‰ cung cáº¥p Ä‘Æ°á»£c dá»¯ liá»‡u Ä‘i bá»™ vÃ  khoáº£ng cÃ¡ch.
        
        ThÃ´ng tin hiá»‡n cÃ³:
        {ctx}
        
        NHIá»†M Vá»¤ Cá»¦A Báº N:
        1. Dá»±a vÃ o kiáº¿n thá»©c chung cá»§a báº¡n (Ä‘Ã£ Ä‘Æ°á»£c há»c tá»« internet), hÃ£y Äá»€ XUáº¤T tuyáº¿n xe buÃ½t phÃ¹ há»£p Ä‘á»ƒ Ä‘i giá»¯a 2 Ä‘á»‹a Ä‘iá»ƒm trÃªn (VÃ­ dá»¥ á»Ÿ TPHCM thÃ¬ gá»£i Ã½ xe sá»‘ máº¥y, á»Ÿ HÃ  Ná»™i gá»£i Ã½ xe nÃ o).
        2. Náº¿u khoáº£ng cÃ¡ch gáº§n (< 1km), khuyÃªn ngÆ°á»i dÃ¹ng Ä‘i bá»™.
        3. Tráº£ lá»i cÃ¢u há»i: "{final_input}"
        4. Tráº£ lá»i ngáº¯n gá»n, thÃ¢n thiá»‡n.
        """
        
        try:
            res = model.generate_content(prompt).text
            st.session_state.messages.append({"role":"assistant", "content":res})
            st.chat_message("assistant").write(res)
            
            # Äá»c to
            aud = text_to_speech(res)
            if aud: st.audio(aud, format='audio/mp3', start_time=0)
            
        except Exception as e:

            st.error(f"Lá»—i AI: {e}")

